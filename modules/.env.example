# AlphaCore Environment Configuration
# Copy this file to .env and customize for your setup
#
# Quick start:
#   cp .env.example .env
#   nano .env
#
# See README.md for detailed configuration guide

# ============================================
# PRODUCTION: OpenAI API Configuration
# ============================================
# Use this for production deployments with OpenAI's hosted API
# Get your API key from: https://platform.openai.com/api-keys
#
# Required:
OPENAI_API_KEY=sk-proj-YOUR_API_KEY_HERE

# Optional (defaults shown):
ALPHACORE_TASK_PROMPT_MODEL=gpt-4o-mini
ALPHACORE_LLM_TEMPERATURE=0.6
ALPHACORE_LLM_RETRIES=2

# Note: Do NOT set OPENAI_BASE_URL for production (uses default: https://api.openai.com/v1)

# ============================================
# DEVELOPMENT: Local Ollama Setup
# ============================================
# Use this for free local LLM inference during development
# Install: dev-scripts/llm-server/start.sh
#
# OPENAI_API_KEY=ollama
# OPENAI_BASE_URL=http://localhost:11434/v1
# ALPHACORE_TASK_PROMPT_MODEL=llama3.1:70b-instruct-q4_K_M

# === LLM Generation Settings ===
ALPHACORE_LLM_TEMPERATURE=0.6
ALPHACORE_LLM_RETRIES=3
ALPHACORE_ENABLE_LLM=true
ALPHACORE_LLM_FALLBACK=true

# ============================================
# Task Configuration
# ============================================
# Control which tasks can be generated and assigned.
# Principle: If not explicitly enabled, it's disabled (whitelist approach).
#
# PROVIDER CONTROL:
# ALPHACORE_ENABLED_PROVIDERS=gcp
# Available providers: gcp, aws, azure
# Default: gcp (only GCP is currently implemented)
#
# TASK TYPE CONTROL:
# ALPHACORE_ENABLED_TASK_TYPES=single_resource_bank,composite_resource_bank
# Available task types:
#   - single_resource_bank: Single resource tasks
#   - composite_resource_bank: Multi-resource tasks (2-3 resources)
# Default: all enabled (if not set, both types are used)
#
# RESOURCE TYPE CONTROL (GCP):
# ALPHACORE_ENABLED_RESOURCE_TYPES=storage_bucket,pubsub_topic,iam_binding
# Available GCP resources:
#   - storage_bucket: Cloud Storage buckets
#   - pubsub_topic: Pub/Sub topics
#   - pubsub_subscription: Pub/Sub subscriptions
#   - artifact_repository: Artifact Registry repositories
#   - service_account: Service accounts
#   - project_iam_member: IAM project bindings
#   - bucket_iam_member: IAM bucket bindings
#   - compute_instance_basic: Compute Engine instances
#   - network: VPC networks
#   - subnetwork: VPC subnets
#   - firewall: VPC firewall rules
#   - dns_managed_zone: Cloud DNS zones
#   - storage_bucket_object: Storage objects
# Default: all enabled (if not set, all resources can be used)
#
# COMPOSITION FAMILY CONTROL:
# ALPHACORE_ENABLED_COMPOSITION_FAMILIES=storage_analytics,artifact_delivery
# Available composition families:
#   - storage_analytics: Storage + Pub/Sub for data pipelines
#   - artifact_delivery: Artifact Registry + Pub/Sub for CI/CD
#   - network_isolation: VPC + Subnet + Firewall for security
#   - compute_deployment: Compute + networking resources
#   - iam_security: Service accounts + IAM bindings
#   - data_pipeline: Data processing workflows
#   - serverless_app: Serverless application stacks
# Default: all enabled (if not set, all families can be used)
#
# RESOURCE COUNT CONSTRAINTS (for composite tasks):
# ALPHACORE_MIN_RESOURCES=1
# ALPHACORE_MAX_RESOURCES=3
# Default: 1-3 resources per composite task
